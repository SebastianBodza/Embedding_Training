{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#os.environ[\"NCCL_P2P_DISABLE\"]=\"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,2\"\n",
    "prompt_template = \"\"\"You have been assigned a retrieval task about {topic}. \n",
    "With the following queries: \n",
    "{questions}\n",
    "\n",
    "Produce two german document, each at least 100 words long, on the subject of {topic}. These documents should be composed in a style that mirrors the type of content one would typically find when searching for answers to a question, such as a Wikipedia article, blog post, news article, list, advertisement etc. Never create documents that only advice on how or where to search for information! For example, if the query is \"Search for information about the history of Berlin\", the document should provide a detailed account of Berlin's history, rather than general advice on how to search for historical information. The style of the documents should mimic the type of results that the question is searching for. Both texts should be of similar length to ensure consistency when comparing them.\n",
    "\n",
    "The first document serves as a 'hard negative' example. It should discuss close to the topic of {topic}, but it should never answer the queries!:\n",
    "{questions}\n",
    "Again the hard negative should never provide the answer to the query. For instance, if the query is \"When is Costco open?\", the hard negative example might discuss the opening hours of Walmart instead.\n",
    "\n",
    "The second document should act as a 'positive' example. It should directly answer the queries:\n",
    "{questions}\n",
    "This document should be informative and precise, offering a specific answer or solution to the queries. Always create both documents in german!\"\"\"# prompt_template = \"\"\"You have been assigned a retrieval task {topic}\n",
    "# With the following queries: \n",
    "# {questions}\n",
    "\n",
    "# Your mission is to write one text retrieval example for this task with the following elements:\n",
    "# - \"positive_document\": a relevant document for the query.\n",
    "# - \"hard_negative_document\": a hard negative document that only appears relevant to the query.\n",
    "\n",
    "# Please adhere to the following guidelines:\n",
    "# - All documents must be created independent of the query. Avoid copying the query verbatim. It’s acceptable if some parts of the \"positive_document\" are not topically related to the query.\n",
    "# - All documents should be at least 100 words long.\n",
    "# - The \"hard_negative_document\" contains some useful information, but it should be less useful or comprehensive compared to the \"positive_document\".\n",
    "# - The documents should be in german.\n",
    "# - Do not provide any explanation in any document on why it is relevant or not relevant to the query.\n",
    "\n",
    "# - Both the query and documents require college level education to understand.\"\"\"\n",
    "\n",
    "\n",
    "response_template = \"\"\"Hard negative german document (not containing the viable information for the queries!):\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 02-07 21:33:51 config.py:549] Casting torch.bfloat16 to torch.float16.\n",
      "WARNING 02-07 21:33:51 config.py:177] gptq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 21:33:54,387\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-07 21:33:55 llm_engine.py:72] Initializing an LLM engine with config: model='TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ', tokenizer='TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ', tokenizer_mode=auto, revision=gptq-4bit-32g-actorder_True, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=16000, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=False, quantization=gptq, enforce_eager=False, kv_cache_dtype=auto, seed=0)\n",
      "WARNING 02-07 21:33:59 custom_all_reduce.py:44] Custom allreduce is disabled because your platform lacks GPU P2P capability. To slience this warning, specifydisable_custom_all_reduce=True explicitly.\n",
      "\u001b[36m(RayWorkerVllm pid=36128)\u001b[0m WARNING 02-07 21:33:59 custom_all_reduce.py:44] Custom allreduce is disabled because your platform lacks GPU P2P capability. To slience this warning, specifydisable_custom_all_reduce=True explicitly.\n",
      "\u001b[36m(RayWorkerVllm pid=36128)\u001b[0m INFO 02-07 21:34:00 weight_utils.py:164] Using model weights format ['*.safetensors']\n",
      "INFO 02-07 21:34:01 weight_utils.py:164] Using model weights format ['*.safetensors']\n",
      "INFO 02-07 21:34:15 llm_engine.py:322] # GPU blocks: 1940, # CPU blocks: 4096\n",
      "INFO 02-07 21:34:17 model_runner.py:632] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-07 21:34:17 model_runner.py:636] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=36128)\u001b[0m INFO 02-07 21:34:17 model_runner.py:632] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=36128)\u001b[0m INFO 02-07 21:34:17 model_runner.py:636] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayWorkerVllm pid=36128)\u001b[0m [W CUDAGraph.cpp:145] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())\n",
      "[W CUDAGraph.cpp:145] Warning: Waiting for pending NCCL work to finish before starting graph capture. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayWorkerVllm pid=36128)\u001b[0m INFO 02-07 21:34:52 model_runner.py:698] Graph capturing finished in 35 secs.\n",
      "INFO 02-07 21:34:52 model_runner.py:698] Graph capturing finished in 35 secs.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import vllm \n",
    "import pandas as pd \n",
    "from vllm import SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ\"\n",
    "sampling_params = SamplingParams(temperature=0.1, max_tokens=16000)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "llm = vllm.LLM(model=model_name, quantization=\"gptq\", \n",
    "               #device=\"cuda:0,cuda:2\",\n",
    "               dtype=torch.float16, \n",
    "               tensor_parallel_size=2, \n",
    "               max_model_len=16000, \n",
    "               revision=\"gptq-4bit-32g-actorder_True\", \n",
    "               gpu_memory_utilization=0.75, \n",
    "               # enforce_eager=True, \n",
    "               # disable_custom_all_reduce=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "df = pd.read_parquet(\"03_parsed_questions.parquet\")\n",
    "df[[\"Positive\", \"Hard Negative\"]] = np.nan\n",
    "df = df.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 32/32 [02:30<00:00,  4.69s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:26<00:00,  4.57s/it]6s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:01<00:00,  3.79s/it]0s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:06<00:00,  3.94s/it]2s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:20<00:00,  4.38s/it]7s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.02s/it]7s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.19s/it]6s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:19<00:00,  4.35s/it]0s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:12<00:00,  4.15s/it]6s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:15<00:00,  4.22s/it]4s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:12<00:00,  4.13s/it]15s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:00<00:00,  3.75s/it]36s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:22<00:00,  4.46s/it]20s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:13<00:00,  4.16s/it]13s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:05<00:00,  3.91s/it]01s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.11s/it]51s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.09s/it]70s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:00<00:00,  3.77s/it]64s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:30<00:00,  4.70s/it]50s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:30<00:00,  4.69s/it]21s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:18<00:00,  4.31s/it]83s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:01<00:00,  3.81s/it]45s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.12s/it]37s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:02<00:00,  3.84s/it]75s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:18<00:00,  4.32s/it]61s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:18<00:00,  4.32s/it]03s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.09s/it]72s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.02s/it]3.71s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.01s/it]2.40s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:16<00:00,  4.26s/it]1.30s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:56<00:00,  3.64s/it]2.95s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:04<00:00,  3.90s/it]8.19s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:23<00:00,  4.49s/it]7.31s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:03<00:00,  3.87s/it]2.40s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:17<00:00,  4.30s/it]9.95s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:30<00:00,  4.71s/it]2.44s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.00s/it]8.10s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.03s/it]5.26s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.09s/it]3.55s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:59<00:00,  3.73s/it]2.91s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:19<00:00,  4.36s/it]8.97s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:34<00:00,  4.81s/it]2.29s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:20<00:00,  4.40s/it]8.98s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:06<00:00,  3.94s/it]9.71s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:13<00:00,  4.17s/it]5.84s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:38<00:00,  4.95s/it]5.29s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:15<00:00,  4.25s/it]2.34s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:20<00:00,  4.40s/it]0.58s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.04s/it]0.81s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:13<00:00,  4.16s/it]7.52s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:15<00:00,  4.25s/it]6.33s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:19<00:00,  4.35s/it]6.38s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:15<00:00,  4.24s/it]7.40s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:19<00:00,  4.37s/it]7.01s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:06<00:00,  3.95s/it]7.97s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:24<00:00,  4.53s/it]4.67s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:12<00:00,  4.15s/it]7.90s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:58<00:00,  3.70s/it]6.52s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  3.98s/it]1.22s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:05<00:00,  3.91s/it]0.26s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.10s/it]8.90s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.19s/it]9.72s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:43<00:00,  5.10s/it]1.20s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:26<00:00,  4.57s/it]1.01s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:03<00:00,  3.85s/it]2.75s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  3.98s/it]7.07s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:27<00:00,  4.61s/it]4.36s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.01s/it]8.48s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:05<00:00,  3.91s/it]5.59s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:54<00:00,  3.59s/it]2.58s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:01<00:00,  3.80s/it]7.40s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:52<00:00,  3.51s/it]5.80s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:56<00:00,  3.63s/it]1.91s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:13<00:00,  4.16s/it]0.34s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.21s/it]4.30s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:16<00:00,  4.25s/it]7.59s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:04<00:00,  3.90s/it]0.30s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:53<00:00,  3.56s/it]8.83s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:59<00:00,  3.74s/it]4.51s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:45<00:00,  3.31s/it]3.25s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:47<00:00,  3.35s/it]8.17s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:57<00:00,  3.68s/it]5.05s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:51<00:00,  3.48s/it]6.00s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:54<00:00,  3.58s/it]4.81s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:15<00:00,  4.25s/it]4.86s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:22<00:00,  4.44s/it]1.37s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.09s/it]7.74s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:04<00:00,  3.90s/it]8.80s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:21<00:00,  4.43s/it]7.81s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:13<00:00,  4.16s/it]2.16s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:02<00:00,  3.84s/it]2.65s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:12<00:00,  4.13s/it]9.91s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:17<00:00,  4.30s/it]0.72s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  4.00s/it]2.95s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:40<00:00,  3.15s/it]1.60s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:58<00:00,  3.72s/it]2.51s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:03<00:00,  3.85s/it]1.61s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:26<00:00,  4.56s/it]2.27s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:25<00:00,  4.55s/it]9.55s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:36<00:00,  4.89s/it]4.49s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.05s/it]41.23s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:18<00:00,  4.33s/it]37.89s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.11s/it]38.28s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:35<00:00,  4.87s/it]36.45s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:24<00:00,  4.51s/it]42.45s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [08:06<00:00, 15.20s/it]43.21s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.01s/it]46.34s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  3.99s/it]11.10s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:00<00:00,  3.76s/it]86.20s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.19s/it]66.62s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:52<00:00,  3.52s/it]57.04s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:00<00:00,  3.77s/it]43.85s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:21<00:00,  4.41s/it]37.09s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:06<00:00,  3.96s/it]38.49s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:49<00:00,  3.42s/it]35.08s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:02<00:00,  3.84s/it]27.52s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:28<00:00,  4.65s/it]26.28s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.02s/it]33.17s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [08:07<00:00, 15.25s/it] 2.01s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:13<00:00,  4.16s/it]38.96s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:51<00:00,  3.49s/it]07.41s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:54<00:00,  3.58s/it]78.88s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:12<00:00,  4.15s/it]59.75s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:06<00:00,  3.94s/it]51.88s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:02<00:00,  3.83s/it]44.30s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:01<00:00,  3.79s/it]37.90s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.11s/it]33.11s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.21s/it]32.80s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:20<00:00,  4.40s/it]33.57s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:17<00:00,  4.31s/it]35.91s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.09s/it]36.65s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.02s/it]35.07s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.21s/it]33.35s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:56<00:00,  3.65s/it]33.94s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:58<00:00,  3.70s/it]28.97s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  3.97s/it]25.97s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.09s/it]26.48s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:24<00:00,  4.50s/it]27.98s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.04s/it]32.95s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:25<00:00,  4.56s/it]31.98s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:17<00:00,  4.30s/it]36.38s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:16<00:00,  4.26s/it]36.94s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:29<00:00,  4.69s/it]36.90s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.04s/it]40.98s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:05<00:00,  3.93s/it]37.60s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:06<00:00,  3.96s/it]34.22s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:23<00:00,  4.49s/it]32.14s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.09s/it]35.80s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.20s/it]34.46s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:17<00:00,  4.30s/it]34.57s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:01<00:00,  3.80s/it]35.69s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:04<00:00,  3.89s/it]31.60s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:27<00:00,  4.61s/it]29.63s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:04<00:00,  3.89s/it]35.19s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:17<00:00,  4.31s/it]32.13s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.08s/it]34.03s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:00<00:00,  3.77s/it]33.15s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.01s/it]29.56s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:05<00:00,  3.92s/it]29.35s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:19<00:00,  4.35s/it]28.37s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:22<00:00,  4.47s/it]31.84s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  3.97s/it]35.34s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:25<00:00,  4.55s/it]33.02s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.22s/it]36.93s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.10s/it]36.49s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:20<00:00,  4.40s/it]35.02s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:13<00:00,  4.17s/it]36.89s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.12s/it]36.07s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.06s/it]34.96s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:22<00:00,  4.47s/it]33.66s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:12<00:00,  4.15s/it]36.63s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.21s/it]35.65s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:24<00:00,  4.50s/it]35.51s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:57<00:00,  3.69s/it]38.27s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.08s/it]32.37s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:56<00:00,  3.66s/it]31.98s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  3.98s/it]27.65s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:02<00:00,  3.83s/it]27.77s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:57<00:00,  3.66s/it]26.33s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.09s/it]23.75s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.12s/it]26.03s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.20s/it]27.93s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:22<00:00,  4.46s/it]30.00s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:17<00:00,  4.29s/it]34.00s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:37<00:00,  4.92s/it]35.15s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:33<00:00,  4.79s/it]42.03s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:29<00:00,  4.68s/it]45.56s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:37<00:00,  4.92s/it]46.94s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:04<00:00,  3.90s/it]50.26s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:57<00:00,  3.69s/it]42.77s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:04<00:00,  3.89s/it]35.51s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.06s/it]32.40s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.10s/it]31.78s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:57<00:00,  3.66s/it]31.78s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:15<00:00,  4.24s/it]27.56s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:17<00:00,  4.28s/it]30.18s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:01<00:00,  3.81s/it]32.40s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.20s/it]29.41s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:02<00:00,  3.82s/it]31.10s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:18<00:00,  4.32s/it]28.59s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:16<00:00,  4.28s/it]31.67s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:16<00:00,  4.27s/it]33.39s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:27<00:00,  4.61s/it]34.53s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.20s/it]38.64s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.08s/it]37.58s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.01s/it]35.61s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:15<00:00,  4.23s/it]33.58s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:57<00:00,  3.68s/it]34.30s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  4.00s/it]29.53s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.03s/it]29.23s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:01<00:00,  3.80s/it]29.35s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:56<00:00,  3.64s/it]27.17s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.04s/it]24.14s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:02<00:00,  3.83s/it]25.84s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:05<00:00,  3.91s/it]25.01s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:04<00:00,  3.88s/it]25.18s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:19<00:00,  4.37s/it]25.09s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:55<00:00,  3.60s/it]29.70s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:20<00:00,  4.40s/it]25.52s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.22s/it]30.28s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:59<00:00,  3.73s/it]31.84s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:18<00:00,  4.33s/it]28.23s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:59<00:00,  3.74s/it]31.48s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:05<00:00,  3.93s/it]28.10s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:21<00:00,  4.41s/it]27.57s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.21s/it]31.79s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.12s/it]32.86s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:16<00:00,  4.26s/it]32.75s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.21s/it]33.95s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:03<00:00,  3.85s/it]34.32s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:06<00:00,  3.95s/it]31.13s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:58<00:00,  3.69s/it]29.94s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:00<00:00,  3.77s/it]26.59s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.06s/it]24.95s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:20<00:00,  4.38s/it]26.65s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:26<00:00,  4.57s/it]30.91s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.19s/it]35.66s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:28<00:00,  4.63s/it]35.35s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:17<00:00,  4.29s/it]39.40s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [08:07<00:00, 15.24s/it] 8.95s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.19s/it]43.70s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:04<00:00,  3.88s/it]11.02s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:54<00:00,  3.59s/it]85.17s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.09s/it]64.25s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:58<00:00,  3.71s/it]54.40s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:12<00:00,  4.15s/it]43.89s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.22s/it]40.74s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:16<00:00,  4.27s/it]39.18s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.11s/it]38.55s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:57<00:00,  3.66s/it]36.61s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:02<00:00,  3.84s/it]30.93s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:16<00:00,  4.27s/it]28.64s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:18<00:00,  4.32s/it]31.23s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.05s/it]33.50s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  3.97s/it]32.47s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [08:03<00:00, 15.11s/it]31.05s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.04s/it]36.95s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.19s/it]04.82s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:11<00:00,  4.10s/it]83.75s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  3.99s/it]68.17s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:10<00:00,  4.09s/it]56.17s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:58<00:00,  3.70s/it]48.77s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:56<00:00,  3.64s/it]39.83s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:31<00:00,  4.75s/it]132.98s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:03<00:00,  3.86s/it]138.83s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:18<00:00,  4.32s/it]134.45s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:41<00:00,  5.06s/it]135.82s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:52<00:00,  3.52s/it]143.81s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:56<00:00,  3.63s/it]134.67s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:20<00:00,  4.38s/it]129.27s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:04<00:00,  3.89s/it]132.69s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:01<00:00,  3.81s/it]130.42s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.20s/it]128.02s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:57<00:00,  3.67s/it]130.13s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:46<00:00,  3.34s/it]126.49s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:00<00:00,  3.78s/it]120.75s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:55<00:00,  3.62s/it]120.98s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [01:47<00:00,  3.35s/it]119.59s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.19s/it]116.10s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:03<00:00,  3.87s/it]121.64s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:03<00:00,  3.86s/it]122.51s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:19<00:00,  4.35s/it]123.02s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:42<00:00,  5.07s/it]128.05s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:06<00:00,  3.95s/it]138.44s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:20<00:00,  4.39s/it]135.04s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:25<00:00,  4.55s/it]136.81s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:18<00:00,  4.33s/it]139.63s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:15<00:00,  4.23s/it]139.53s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:06<00:00,  3.97s/it]138.42s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:02<00:00,  3.84s/it]135.15s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:01<00:00,  3.79s/it]131.65s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.00s/it]128.72s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:12<00:00,  4.13s/it]128.71s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:37<00:00,  4.92s/it]129.90s/it]\n",
      "Processed prompts: 100%|██████████| 32/32 [02:09<00:00,  4.03s/it]138.29s/it]\n",
      "Processing batches:  21%|██        | 295/1405 [11:13:09<42:12:53, 136.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m batches \u001b[38;5;241m=\u001b[39m df_nan[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImperative Form\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch String\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mBATCH_SIZE]\n\u001b[1;32m     23\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m[generate_prompt(batch) \u001b[38;5;28;01mfor\u001b[39;00m n, batch \u001b[38;5;129;01min\u001b[39;00m batches\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[0;32m---> 24\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m results_adj \u001b[38;5;241m=\u001b[39m [result\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m result\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m     26\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[batches\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_texts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m results_adj\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/vllm/entrypoints/llm.py:182\u001b[0m, in \u001b[0;36mLLM.generate\u001b[0;34m(self, prompts, sampling_params, prompt_token_ids, prefix_pos, use_tqdm, lora_request)\u001b[0m\n\u001b[1;32m    175\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m prompt_token_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m prompt_token_ids[\n\u001b[1;32m    176\u001b[0m         i]\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_request(prompt,\n\u001b[1;32m    178\u001b[0m                       sampling_params,\n\u001b[1;32m    179\u001b[0m                       token_ids,\n\u001b[1;32m    180\u001b[0m                       lora_request\u001b[38;5;241m=\u001b[39mlora_request,\n\u001b[1;32m    181\u001b[0m                       prefix_pos\u001b[38;5;241m=\u001b[39mprefix_pos_i)\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/vllm/entrypoints/llm.py:208\u001b[0m, in \u001b[0;36mLLM._run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m    206\u001b[0m outputs: List[RequestOutput] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mhas_unfinished_requests():\n\u001b[0;32m--> 208\u001b[0m     step_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/vllm/engine/llm_engine.py:796\u001b[0m, in \u001b[0;36mLLMEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    792\u001b[0m seq_group_metadata_list, scheduler_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mschedule()\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheduler_outputs\u001b[38;5;241m.\u001b[39mis_empty():\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;66;03m# Execute the model.\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m     all_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq_group_metadata_list\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_group_metadata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblocks_to_swap_in\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks_to_swap_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblocks_to_swap_out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks_to_swap_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblocks_to_copy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks_to_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;66;03m# Only the driver worker returns the sampling results.\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     output \u001b[38;5;241m=\u001b[39m all_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/vllm/engine/llm_engine.py:983\u001b[0m, in \u001b[0;36mLLMEngine._run_workers\u001b[0;34m(self, method, driver_args, driver_kwargs, max_concurrent_workers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m     driver_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m    982\u001b[0m \u001b[38;5;66;03m# Start the driver worker after all the ray workers.\u001b[39;00m\n\u001b[0;32m--> 983\u001b[0m driver_worker_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdriver_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdriver_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# Get the results of the ray workers.\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers:\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/vllm/worker/worker.py:213\u001b[0m, in \u001b[0;36mWorker.execute_model\u001b[0;34m(self, seq_group_metadata_list, blocks_to_swap_in, blocks_to_swap_out, blocks_to_copy)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_seq_groups \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[0;32m--> 213\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_group_metadata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/vllm/worker/model_runner.py:542\u001b[0m, in \u001b[0;36mModelRunner.execute_model\u001b[0;34m(self, seq_group_metadata_list, kv_caches)\u001b[0m\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m model_executable(\n\u001b[1;32m    535\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_tokens,\n\u001b[1;32m    536\u001b[0m     positions\u001b[38;5;241m=\u001b[39minput_positions,\n\u001b[1;32m    537\u001b[0m     kv_caches\u001b[38;5;241m=\u001b[39mkv_caches,\n\u001b[1;32m    538\u001b[0m     input_metadata\u001b[38;5;241m=\u001b[39minput_metadata,\n\u001b[1;32m    539\u001b[0m )\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# Sample the next token.\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/vllm/model_executor/models/mixtral_quant.py:365\u001b[0m, in \u001b[0;36mMixtralForCausalLM.sample\u001b[0;34m(self, hidden_states, sampling_metadata)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    362\u001b[0m     hidden_states: Optional[torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    363\u001b[0m     sampling_metadata: SamplingMetadata,\n\u001b[1;32m    364\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[SamplerOutput]:\n\u001b[0;32m--> 365\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m                               \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_tokens\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:108\u001b[0m, in \u001b[0;36mSampler.forward\u001b[0;34m(self, embedding, hidden_states, sampling_metadata, embedding_bias)\u001b[0m\n\u001b[1;32m    105\u001b[0m logprobs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Sample the next tokens.\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m sample_results \u001b[38;5;241m=\u001b[39m \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Get the logprobs query results.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m prompt_logprobs, sample_logprobs \u001b[38;5;241m=\u001b[39m _get_logprobs(\n\u001b[1;32m    111\u001b[0m     logprobs, sampling_metadata, sample_results)\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:411\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(probs, logprobs, sampling_metadata)\u001b[0m\n\u001b[1;32m    409\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m _greedy_sample(seq_groups, greedy_samples)\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;241m==\u001b[39m SamplingType\u001b[38;5;241m.\u001b[39mRANDOM:\n\u001b[0;32m--> 411\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m \u001b[43m_random_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmultinomial_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;241m==\u001b[39m SamplingType\u001b[38;5;241m.\u001b[39mBEAM:\n\u001b[1;32m    414\u001b[0m     sample_results \u001b[38;5;241m=\u001b[39m _beam_search_sample(seq_groups, is_prompts,\n\u001b[1;32m    415\u001b[0m                                          sampling_metadata\u001b[38;5;241m.\u001b[39mseq_data,\n\u001b[1;32m    416\u001b[0m                                          beam_search_logprobs)\n",
      "File \u001b[0;32m~/miniforge3/envs/qnovi_app/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:263\u001b[0m, in \u001b[0;36m_random_sample\u001b[0;34m(selected_seq_groups, is_prompts, random_samples)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_random_sample\u001b[39m(\n\u001b[1;32m    258\u001b[0m     selected_seq_groups: List[Tuple[List[\u001b[38;5;28mint\u001b[39m], SamplingParams]],\n\u001b[1;32m    259\u001b[0m     is_prompts: List[\u001b[38;5;28mbool\u001b[39m],\n\u001b[1;32m    260\u001b[0m     random_samples: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[List[\u001b[38;5;28mint\u001b[39m], List[\u001b[38;5;28mint\u001b[39m]]]:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# Find the maximum best_of value of the prompt phase requests.\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     random_samples \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    265\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def generate_prompt(row):\n",
    "    row = row.fillna(\"\")\n",
    "    questions = \"\\n\".join(row[[\"Imperative Form\", \"Question\", \"Search String\"]].str.removesuffix('\"').str.removeprefix('\"').to_list())\n",
    "    topic = row[\"topic\"]\n",
    "    formatted_prompt = tokenizer.apply_chat_template(conversation=[\n",
    "        {\"role\": \"user\", \"content\":prompt_template.replace(\"{questions}\", str(questions)).replace(\"{topic}\", str(topic))},\n",
    "        {\"role\": \"assistant\", \"content\":response_template}\n",
    "        ], tokenize=False)\n",
    "    formatted_prompt = formatted_prompt.removesuffix(\"</s>\")\n",
    "    return formatted_prompt\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "df = pd.read_parquet(\"04_results_texts_v5.parquet\")\n",
    "df_nan = df[df[\"raw_texts\"]==\"nan\"]\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, len(df_nan), BATCH_SIZE), desc=\"Processing batches\"):\n",
    "    batches = df_nan[[\"topic\", \"Imperative Form\", \"Question\", \"Search String\"]].iloc[i:i+BATCH_SIZE]\n",
    "    formatted_prompt =[generate_prompt(batch) for n, batch in batches.iterrows()]\n",
    "    results = llm.generate(formatted_prompt, sampling_params=sampling_params)\n",
    "    results_adj = [result.prompt.split(\"[/INST]\")[-1]+ result.outputs[0].text for result in results]\n",
    "    df.loc[batches.index, 'raw_texts'] = results_adj\n",
    "    df.to_parquet(\"04_results_texts_v5.parquet\")   \n",
    "\n",
    "\n",
    "# vllm 0.2.7\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:03<00:00,  3.87s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:15<00:00,  4.25s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.21s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:17<00:00,  4.31s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  3.98s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:16<00:00,  4.28s/it]\n",
    "\n",
    "# vllm 0.3: disable cuda graph & all reduce\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:13<00:00,  4.17s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:39<00:00,  4.99s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:05<00:00,  3.93s/it]\n",
    "    \n",
    "# vllm 0.3: disable all reduce\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:14<00:00,  4.22s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:07<00:00,  3.99s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:03<00:00,  3.86s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:00<00:00,  3.78s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:01<00:00,  3.80s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [01:56<00:00,  3.65s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.01s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:13<00:00,  4.16s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:08<00:00,  4.03s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [01:53<00:00,  3.54s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [01:45<00:00,  3.28s/it]\n",
    "# Processed prompts: 100%|██████████| 32/32 [02:00<00:00,  3.76s/it]\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnovi_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
