{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Generate two texts related to the topic of {topic}, both written in German and each being at least 400 words long.\n",
    "\n",
    "The first text should be a hard negative example. It must be semantically or syntactically similar to the question or search string related to {topic}, but it cannot contain the answer to the question: \n",
    "{questions}\n",
    "This text should engage with the topic in a way that is relevant but carefully avoids providing the answer. The hard negative example must never contain the answer to the questions!\n",
    "\n",
    "The second text should be a positive example. It must directly address and provide the answer to the question: \n",
    "{questions}\n",
    "This text should be a factual and informative piece that thoroughly covers the topic.\n",
    "\n",
    "Both texts should be of similar length to ensure consistency in comparison and should be written in German.\n",
    "\"\"\"\n",
    "\n",
    "response_template = \"\"\"Hard Positive Example (not containing the answer!):\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "\n",
    "formatted_prompt = tokenizer.apply_chat_template(conversation=[\n",
    "    {\"role\": \"user\", \"content\":prompt_template.replace(\"{TOPICCC}\", str(questions))},\n",
    "    {\"role\": \"assistant\", \"content\":response_template.replace(\"{TOPICCC}\", str(questions))}\n",
    "    ], tokenize=False)\n",
    "formatted_prompt = formatted_prompt.removesuffix(\"</s>\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
